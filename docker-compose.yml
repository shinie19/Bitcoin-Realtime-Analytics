version: "3.8"

services:
  # Airflow
  postgres:
    image: postgres
    container_name: postgres
    ports:
      - "5432:5432"
    environment:
      - POSTGRES_USER=airflow
      - POSTGRES_PASSWORD=airflow
      - POSTGRES_DB=airflow
    volumes:
      - postgres-data:/var/lib/postgresql/data/
    networks:
      - pipeline-net

  scheduler:
    image: shinie19/airflow:v1.0.2
    container_name: scheduler
    volumes:
      - ./airflow:/airflow/
    networks:
      - pipeline-net
    depends_on:
      - postgres
    environment:
      - POSTGRES_HOST=postgres
      - POSTGRES_PORT=5432
      - POSTGRES_USER=airflow
      - POSTGRES_PASSWORD=airflow
      - AIRFLOW__CORE__LOAD_EXAMPLES=False
    command: ["airflow", "scheduler"]

  webserver:
    image: shinie19/airflow:v1.0.2
    container_name: webserver
    entrypoint: ./entrypoint.sh
    ports:
      - "8080:8080"
    volumes:
      - ./airflow:/airflow/
    networks:
      - pipeline-net
    depends_on:
      - postgres
      - scheduler
    environment:
      - POSTGRES_HOST=postgres
      - POSTGRES_PORT=5432
      - POSTGRES_USER=airflow
      - POSTGRES_PASSWORD=airflow
      - POSTGRES_DB=airflow
      - AIRFLOW__CORE__LOAD_EXAMPLES=False

  # Zookeeper
  zookeeper:
    image: confluentinc/cp-zookeeper:latest
    hostname: zookeeper
    container_name: zookeeper
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000
    ports:
      - 2181:2181
    networks:
      - pipeline-net

  kafka:
    image: confluentinc/cp-kafka:latest
    hostname: kafka
    container_name: kafka
    depends_on:
      - zookeeper
    restart: unless-stopped
    ports:
      - 29092:29092
      - 9092:9092
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:9092,PLAINTEXT_HOST://localhost:29092
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
      KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_AUTO_CREATE_TOPICS_ENABLE: "true"
    networks:
      - pipeline-net

  kafka-connect:
    image: confluentinc/cp-kafka-connect
    container_name: kafka-connect
    hostname: kafka-connect
    depends_on:
      - zookeeper
      - kafka
    ports:
      - "8083:8083"
    environment:
      CONNECT_BOOTSTRAP_SERVERS: "kafka:9092"
      CONNECT_ZOOKEEPER_CONNECT: "zookeeper:2181"
      CONNECT_REST_ADVERTISED_HOST_NAME: "kafka-connect"
      CONNECT_REST_PORT: 8083
      CONNECT_GROUP_ID: "connect-cluster"
      CONNECT_CONFIG_STORAGE_TOPIC: "connect-configs"
      CONNECT_OFFSET_STORAGE_TOPIC: "connect-offsets"
      CONNECT_STATUS_STORAGE_TOPIC: "connect-status"
      CONNECT_KEY_CONVERTER: "org.apache.kafka.connect.storage.StringConverter"
      CONNECT_VALUE_CONVERTER: "org.apache.kafka.connect.json.JsonConverter"
      CONNECT_INTERNAL_KEY_CONVERTER: "org.apache.kafka.connect.json.JsonConverter"
      CONNECT_INTERNAL_VALUE_CONVERTER: "org.apache.kafka.connect.json.JsonConverter"
      CONNECT_PLUGIN_PATH: "/usr/share/java,/etc/kafka-connect/jars"

    volumes:
      - ./kafka-connect/jars:/etc/kafka-connect/jars
    networks:
      - pipeline-net

  clickhouse:
    image: yandex/clickhouse-server
    container_name: clickhouse
    hostname: clickhouse
    restart: always
    ports:
      - "8123:8123"
      - "9000:9000"
    volumes:
      - ./clickhouse/clickhouse-data:/var/lib/clickhouse
    networks:
      - pipeline-net

  grafana:
    image: grafana/grafana
    ports:
      - "3000:3000"
    depends_on:
      - clickhouse
    environment:
      - GF_INSTALL_PLUGINS=vertamedia-clickhouse-datasource
      - GF_AUTH_ANONYMOUS_ENABLED=true
      - GF_AUTH_ANONYMOUS_ORG_ROLE=Admin
    volumes:
      - ./grafana/grafana-data:/var/lib/grafana
    networks:
      - pipeline-net

volumes:
  postgres-data:

networks:
  pipeline-net:
    driver: bridge
